# 🚀 Apache Kafka 정리
 
> ### [토스 테크니컬 라이팅](https://technical-writing.dev/) 내용을 promt로 설정하여 글의 형식생성


---

# 📚 Part 1: Kafka 이해하기

## 1. Kafka란 무엇인가?

### 🎯 핵심 개념

- Kafka를 한 문장으로 설명하면 "엄청나게 빠른 메시지 전달 시스템"입니다.


- 다음과 같은 특징을 가집니다.
    1. Kafka는 다른 메세지 큐와 다르게 메세지를 삭제하지 않고, 디스크에 일정한 기간 동안 보관한다.
    2. 높은 처리량을 가진다 : 파티션 기반 병렬 처리 구조로 대용량 이벤트를 처리할 수 있다.
  3. 내구성 보장 : 메세지를 디스크에 저장하고 복제하여 데이터 손실 방지
  4. 순서 보장 : < 같은 파티션 > 내에서는 메세지 순서를 보장한다.
  



### 💡 왜 Kafka가 필요한가?

- redis를 사용하면 db 부화를 줄일 수 있지만 다음과 같은 단점이 있다.
  1. 즉시처리가 안됨
  2. 유실 가능성이 있다.
  3. 재처리, 수평 확장의 어려움을 가진다.

- 카프카로 구현을 하면 
  1. 안정적인 메세지 보장
  2. 데이터 영속성과 내구성
  3. 수평 확장과 장애복구 -> 파티션 + group + 리벨런싱 + 디스크 스케일업


**기존 방식의 문제점:**
```
주문 서비스 ────→ 결제 서비스
    ↓
재고 서비스 ────→ 배송 서비스
    ↓
알림 서비스 ────→ 분석 서비스
```

이렇게 하면:
- 주문 서비스가 6개 서비스와 직접 통신해야 함
- 하나의 서비스가 죽으면 전체 주문 처리가 멈춤
- 새로운 서비스 추가할 때마다 기존 코드 수정 필요

**Kafka 도입 후:**
```
주문 서비스 ────→ Kafka ────→ 결제 서비스
                    ├────→ 재고 서비스
                    ├────→ 배송 서비스
                    ├────→ 알림 서비스
                    └────→ 분석 서비스
```

이제 주문 서비스는 Kafka에만 메시지를 보내면 됩니다. 다른 서비스들이 죽어도 주문 처리는 계속되고, 나중에 서비스가 살아나면 밀린 메시지를 처리할 수 있습니다.

## 2. Kafka 핵심 아키텍처

### 🔧 주요 구성 요소

#### Broker (브로커)
Kafka 서버입니다. 보통 3대 이상으로 클러스터를 구성합니다.

- 왜 3대?
  - 한 대가 죽어도 서비스가 계속되려면 최소 3대는 있어야 합니다. 실제 운영에서는 홀수 개로 구성하는 게 좋습니다. (split-brain 문제 방지)

#### Topic (토픽)
메시지의 주제입니다. 예를 들면:
- `user-events`: 사용자 행동 데이터
- `order-created`: 주문 생성 이벤트
- `payment-completed`: 결제 완료 이벤트


#### Partition (파티션)

- 토픽을 여러 개로 나눈 것입니다.

- **여기서 중요한 부분은 파티션의 수는 증가는 가능하지만 감소할 수 없다.**

파티션이 3개라면:
```
Topic: user-events
├── Partition 0: [msg1, msg4, msg7, ...]
├── Partition 1: [msg2, msg5, msg8, ...]
└── Partition 2: [msg3, msg6, msg9, ...]
```


#### Producer (프로듀서)

- 메시지를 보내는 애플리케이션입니다.


#### Consumer (컨슈머)
- 메시지를 받는 애플리케이션입니다.

한 가지 중요한 점은, 여러 컨슈머가 같은 토픽을 구독할 수 있다는 것입니다. 예를 들어 `order-created` 토픽을
- 결제 서비스도 구독하고
- 재고 서비스도 구독하고
- 분석 서비스도 구독할 수 있습니다

### 📊 데이터 흐름 다이어그램

실제 메시지가 어떻게 흐르는지 보면:

```
[주문 서비스] 
    ↓ 메시지 전송
[Kafka Cluster]
├── Broker 1 (Leader for Partition 0)
├── Broker 2 (Leader for Partition 1)  
└── Broker 3 (Leader for Partition 2)
    ↓ 메시지 구독
[컨슈머 그룹: 결제팀]
├── Consumer 1 (Partition 0 담당)
├── Consumer 2 (Partition 1 담당)
└── Consumer 3 (Partition 2 담당)
```

중요한 점은 **하나의 파티션은 하나의 컨슈머만** 처리할 수 있다. >>>  그래서 컨슈머를 파티션 수보다 많이 띄워도 일부는 놀게 된다.

---

# 🛠️ Part 2: Kafka 환경 구축하기

## 3. 설치 및 설정

### 🐳 Docker
#### docker-compose.yml 파일 생성

```yaml
version: '3'

networks:
  kafka_network:
    driver: bridge

services:
  zookeeper:
    image: 'bitnami/zookeeper:3.7.2'
    container_name: zookeeper
    networks:
      - kafka_network
    ports:
      - 2181:2181
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - ./.data/zookeeper/data:/bitnami/zookeeper/data
      - ./.data/zookeeper/datalog:/bitnami/zookeeper/datalog
      - ./.data/zookeeper/logs:/bitnami/zookeeper/logs

  kafka1:
    image: 'bitnami/kafka:3.6.0'
    container_name: kafka1
    hostname: kafka1
    networks:
      - kafka_network
    ports:
      - 19092
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:19092,EXTERNAL://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka1:19092,EXTERNAL://localhost:9092
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      - zookeeper
    volumes:
      - ./.data/kafka1:/bitnami/kafka/data
    restart: unless-stopped

  kafka2:
    image: 'bitnami/kafka:3.6.0'
    container_name: kafka2
    hostname: kafka2
    networks:
      - kafka_network
    ports:
      - 19092
      - "9093:9093"
    environment:
      - KAFKA_BROKER_ID=2
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:19092,EXTERNAL://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka2:19092,EXTERNAL://localhost:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      - zookeeper
    volumes:
      - ./.data/kafka2:/bitnami/kafka/data
    restart: unless-stopped

  kafka3:
    image: 'bitnami/kafka:3.6.0'
    container_name: kafka3
    hostname: kafka3
    networks:
      - kafka_network
    ports:
      - 19092
      - "9094:9094"
    environment:
      - KAFKA_BROKER_ID=3
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:19092,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka3:19092,EXTERNAL://localhost:9094
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      - zookeeper
    volumes:
      - ./.data/kafka3:/bitnami/kafka/data
    restart: unless-stopped

  kafka-ui:
    image: 'provectuslabs/kafka-ui:v0.7.1'
    container_name: kafka-ui
    networks:
      - kafka_network
    ports:
      - "8081:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:19092,kafka2:19092,kafka3:19092
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    restart: unless-stopped

  redpanda-console:
    image: 'docker.redpanda.com/redpandadata/console:v2.3.7'
    container_name: redpanda-console
    networks:
      - kafka_network
    ports:
      - "8989:8080"
    environment:
      - KAFKA_BROKERS=kafka1:19092,kafka2:19092,kafka3:19092
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    restart: unless-stopped
```

#### 실행 명령어

```bash
# 클러스터 시작
docker-compose -f docker-compose-kafka.yml up -d

docker ps --format "table {{.ID}}\t{{.Names}}\t{{.Status}}"
```

## 4. 기본 동작 확인

### 📝 토픽 생성하기

```bash
# 토픽 생성
docker exec -it kafka kafka-topics --create \
    --topic test-topic \
    --bootstrap-server localhost:9092 \
    --partitions 3 \
    --replication-factor 1

# 토픽 목록 확인
docker exec -it kafka kafka-topics --list \
    --bootstrap-server localhost:9092

# 토픽 상세 정보 확인  
docker exec -it kafka kafka-topics --describe \
    --topic test-topic \
    --bootstrap-server localhost:9092
```

결과가 이렇게 나오면 성공:
```
Topic: test-topic	TopicId: xxxxx	PartitionCount: 3	ReplicationFactor: 1
	Topic: test-topic	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: test-topic	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: test-topic	Partition: 2	Leader: 1	Replicas: 1	Isr: 1
```

간단한 메시지 테스트:
```bash
# 메시지 보내기 (Producer)
docker exec -it kafka kafka-console-producer \
    --topic test-topic \
    --bootstrap-server localhost:9092

# 메시지 받기 (Consumer, 다른 터미널에서)
docker exec -it kafka kafka-console-consumer \
    --topic test-topic \
    --from-beginning \
    --bootstrap-server localhost:9092
```

Producer 터미널에서 아무 텍스트나 입력하면, Consumer 터미널에서 바로 보이면 설치 성공입니다.

---

# 🔍 Part 3: 핵심 개념 심화 학습

## 5. 파티션과 오프셋 이해하기

### 📊 파티션 개념

파티션을 쉽게 생각하면 "여러 개의 줄 서기"입니다.

```
Topic: user-activity (파티션 3개)

Partition 0: [login, logout, click, ...]
Partition 1: [signup, purchase, ...]  
Partition 2: [view, scroll, click, ...]
```

**중요한 특징:**
- 파티션 **내에서만** 순서가 보장됨
- 파티션이 3개면 최대 3개의 Consumer가 병렬 처리 가능
- 파티션 수는 늘릴 수는 있지만 줄일 수는 없음


### 📍 오프셋 관리

오프셋은 파티션 내에서 메시지의 위치입니다. 0번부터 시작해서 메시지가 추가될 때마다 1씩 증가합니다.

```
Partition 0: [msg0] [msg1] [msg2] [msg3] [msg4] ...
              ↑      ↑      ↑      ↑      ↑
           offset:   0      1      2      3      4
```

**Consumer 오프셋 관리 전략:**

1. **자동 커밋** (기본값)
```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
configs.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000); // 5초마다
```
- 편하지만 메시지 손실 위험 있음
- 처리 도중 Consumer 죽으면 해당 메시지는 다시 처리 안 됨

2. **수동 커밋** (권장)
```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

// 메시지 처리 후
consumer.commitSync(); // 동기 커밋
// 또는
consumer.commitAsync(); // 비동기 커밋
```

**고려해야 되는 부분**
- Consumer가 재시작되면 마지막 커밋된 오프셋부터 시작
- 메시지 처리는 됐는데 커밋 안 되면 중복 처리 발생
- 커밋은 됐는데 처리 안 되면 메시지 손실

## 6. Consumer Group 활용하기

### 👥 Consumer Group 동작 원리

```
Topic: order-events (파티션 3개)

Consumer Group: payment-service
├── Consumer 1 → Partition 0 담당
├── Consumer 2 → Partition 1 담당  
└── Consumer 3 → Partition 2 담당

Consumer Group: analytics-service  
├── Consumer A → Partition 0,1,2 모두 담당
```

같은 Consumer Group 안에서는 하나의 파티션을 하나의 Consumer만 처리합니다. 하지만 다른 Consumer Group은 같은 메시지를 각자 독립적으로 처리할 수 있습니다.

**실제 사용 예시:**
```java
// 결제 서비스
Properties configs = new Properties();
configs.put(ConsumerConfig.GROUP_ID_CONFIG, "payment-service");

// 분석 서비스 (같은 토픽, 다른 그룹)
Properties configs2 = new Properties();  
configs2.put(ConsumerConfig.GROUP_ID_CONFIG, "analytics-service");
```

### ⚖️ 리밸런싱 (Rebalancing)

**언제 발생하나:**
- Consumer 추가/제거
- Consumer 장애로 heartbeat 끊김
- 토픽 파티션 수 변경

**리밸런싱 과정:**
1. 모든 Consumer가 일시적으로 메시지 처리 중단
2. 파티션 재할당
3. Consumer들이 새로운 파티션 담당

```
리밸런싱 전:
Consumer 1 → Partition 0, 1
Consumer 2 → Partition 2

리밸런싱 후 (Consumer 3 추가):
Consumer 1 → Partition 0
Consumer 2 → Partition 1  
Consumer 3 → Partition 2
```